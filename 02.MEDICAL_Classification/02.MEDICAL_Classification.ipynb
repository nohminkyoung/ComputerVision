{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. 이미지 파일경로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import copy\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일경로를 리스트로 받아오는 함수(폴더 이름label도 같이 불러오기 위함)\n",
    "\n",
    "def list_image_files(data_dir, sub_dir):\n",
    "    img_list = []\n",
    "    img_dir = os.path.join(data_dir, sub_dir)\n",
    "\n",
    "    for file in os.listdir(img_dir):\n",
    "        img_list.append(sub_dir+'/'+file)\n",
    "    \n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/MEDICAL-DATASET/Classification/train/\"\n",
    "\n",
    "Normal_list = list_image_files(data_dir,\"Normal\")\n",
    "Covid_list = list_image_files(data_dir,\"Covid\")\n",
    "Viral_list = list_image_files(data_dir,\"Viral Pneumonia\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# 2. 이미지데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Normal_list), len(Covid_list), len(Viral_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 RGB로 받아오는 함수\n",
    "def get_RGB(data_dir, file_name):\n",
    "    img_dir = os.path.join(data_dir, file_name)\n",
    "    img = cv2.cvtColor(cv2.imread(img_dir), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data = min(len(Normal_list), len(Covid_list), len(Viral_list))\n",
    "\n",
    "# img그려주는 함수\n",
    "@interact(index=(0,min_data-1))\n",
    "def show_sample(index=0):\n",
    "    Normal_img = get_RGB(data_dir, Normal_list[index])\n",
    "    Covid_img = get_RGB(data_dir, Covid_list[index])\n",
    "    Viral_img = get_RGB(data_dir, Viral_list[index])\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(131)\n",
    "    plt.title('Normal')\n",
    "    plt.imshow(Normal_img)\n",
    "    plt.subplot(132)\n",
    "    plt.title('Covid')\n",
    "    plt.imshow(Covid_img)\n",
    "    plt.subplot(133)\n",
    "    plt.title('Viral')\n",
    "    plt.imshow(Viral_img) \n",
    "    plt.tight_layout() #그림의 여백을 최적화\n",
    "    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# 3. 데이터셋 구축\n",
    "\n",
    "### 데이터셋 구축의 과정\n",
    "##### 5.1 데이터 셋을 로드하는 클래스 구축\n",
    "##### 5.2 데이터를 텐서형으로 변환\n",
    "##### 5.3 이터레이터 기능을 하는 데이터 로더를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [\"Normal\", \"Covid\", \"Viral Pneumonia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 구현\n",
    "# init, len, getitem이 구현되어야함\n",
    "\n",
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.class_list = [\"Normal\", \"Covid\", \"Viral Pneumonia\"]\n",
    "        self.data_dir = data_dir\n",
    "        Normal_list = list_image_files(self.data_dir,\"Normal\")\n",
    "        Covid_list = list_image_files(self.data_dir,\"Covid\")\n",
    "        Viral_list = list_image_files(self.data_dir,\"Viral Pneumonia\")\n",
    "        \n",
    "\n",
    "        self.all_data_list = Normal_list+Covid_list+Viral_list\n",
    "        self.transform = transform \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_data_list)\n",
    "\n",
    "    def __getitem__(self, index): #RGB데이터와 label불러줌\n",
    "        img = get_RGB(self.data_dir, self.all_data_list[index])\n",
    "        label = self.class_list.index(self.all_data_list[index].split('/')[0])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img) # 이미지를 텐서로 바꿔주는부분\n",
    "            label = torch.Tensor([label]).long() #레이블을 텐서로 바꿔주는 부분\n",
    "        \n",
    "        return {'img':img, 'label':label}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = My_Dataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 200\n",
    "plt.title(class_list[data_set[index]['label']])\n",
    "plt.imshow(data_set[index]['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# 4.텐서형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "                         std=[0.5,0.5,0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환 결과 확인\n",
    "tdata_set = My_Dataset(data_dir, transformer)\n",
    "img = tdata_set[100]['img']\n",
    "label = tdata_set[100]['label']\n",
    "\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# 5. 데이터 로더 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 val데이터를 딕셔너리로 묶어서 데이터 로더 생성\n",
    "# test Data도 label을 알고있어서 같이 구현\n",
    "\n",
    "def My_Dataloader(train_dir, test_dir):\n",
    "    dataloader = {}\n",
    "    train_dataset = My_Dataset(train_dir,transformer)\n",
    "    \n",
    "    # 학습 데이터와 검증 데이터로 분할\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "    \n",
    "    dataloader['train'] = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "    dataloader['val'] = DataLoader(val_dataset, batch_size=4, shuffle=False, drop_last=False)\n",
    "    \n",
    "\n",
    "    test_dataset = My_Dataset(test_dir, transformer)\n",
    "    dataloader['test'] = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../data/MEDICAL-DATASET/Classification/train/'\n",
    "test_dir = '../data/MEDICAL-DATASET/Classification/test/'\n",
    "\n",
    "dataloader = My_Dataloader(train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# 6. VGG 모델 fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(3,224,224),batch_size=4,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC layer를 변경\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(output_size = (1,1)) # 기존의 7,7로 반환되던 avgpool층을 1,1로 반환되도록 변경\n",
    "model.classifier = nn.Sequential( #분류기에 접근 할 때 이 방법도 사용 가능\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,len(class_list)),\n",
    "    nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,(3,224,224),batch_size=4,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# 7. 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='mean') #reduction='mean' : 배치사이즈에 따른 평균값을 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# 8. Gradient최적화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경된 부분만 학습\n",
    "optimizer = torch.optim.SGD([\n",
    "                            {'params': model.avgpool.parameters(), 'lr':0.001},\n",
    "                            {'params': model.classifier.parameters(), 'lr':0.001}],momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# 9. 모델 학습을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "def train_one_epoch(dataloaders, model, optimizer, loss_func, device):\n",
    "    losses={} #한 에폭에서의 평균 loss를 담을 것\n",
    "    accuracy={} #한 에폭에서의 평균 정확도를 담을 것\n",
    "\n",
    "    for ty in ['train','val']:\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        \n",
    "        if ty == 'train':\n",
    "            model.train()\n",
    "        else :\n",
    "            model.eval()\n",
    "\n",
    "        for index, batch in enumerate(dataloaders[ty]):\n",
    "            img = batch['img'].to(device)\n",
    "            label = batch['label'].squeeze(dim=1).to(device)\n",
    "        \n",
    "            with torch.set_grad_enabled(ty=='train'): #train인 경우에만 grad를 갱신\n",
    "                predict = model(img)\n",
    "                loss = loss_func(predict, label)\n",
    "        \n",
    "                _, pred_label = torch.max(predict, dim=1) #predict shape이 (Batch_size, 3_label개수) 이기 때문에 각 label중 최대값만 찾기 위함\n",
    "                is_correct = (pred_label==label).numpy().sum()/len(label) # 정확도: 맞은개수/전체개수\n",
    "        \n",
    "                if ty=='train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "        \n",
    "                running_loss+=loss.item() # 배치별 평균 loss의 합\n",
    "                running_correct += is_correct # 배치별 평균 정확도의 합\n",
    "        \n",
    "                if ty=='train':\n",
    "                    if index%10==0:\n",
    "                        print(f\"{index}/{len(dataloaders[ty])} 의 batch loss : {loss.item()}\")\n",
    "\n",
    "        losses[ty] = running_loss/len(dataloaders[ty]) #에폭당 평균 loss\n",
    "        accuracy[ty] = running_correct/len(dataloaders[ty]) #에폭당 평균 정확도\n",
    "\n",
    "\n",
    "    return losses, accuracy       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(model_state, model_name, save_dir='./trained_model'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# 10. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "best_acc = 0.0\n",
    "train_loss, train_acc = [],[] # 그래프 그리기 위해서 에폭당 손실, 정확도를 담음\n",
    "val_loss, val_acc = [],[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses, accuracies = train_one_epoch(dataloader, model, optimizer, loss_func, device)\n",
    "    train_loss.append(losses['train'])\n",
    "    val_loss.append(losses['val'])\n",
    "    train_acc.append(accuracies['train'])\n",
    "    val_acc.append(accuracies['val'])\n",
    "\n",
    "    print(f\"{epoch+1}/{num_epochs}-Train Loss: {losses['train']}, Val Loss: {losses['val']}\")\n",
    "    print(f\"{epoch+1}/{num_epochs}-Train Acc: {accuracies['train']}, Val Acc: {accuracies['val']}\")\n",
    "\n",
    "    if accuracies['val'] > best_acc:\n",
    "        best_acc = accuracies['val']\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "        save_best_model(best_model, f'best_model.pth')\n",
    "\n",
    "\n",
    "print(f\"Best Accuracy: {best_acc}\")        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.subplot(211)\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.plot(val_loss,  label=\"val\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(train_acc, label=\"train\")\n",
    "plt.plot(val_acc, label=\"val\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# 11. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측값 \n",
    "pred = []\n",
    "for index, batch in enumerate(dataloader['test']):\n",
    "    img = batch['img']\n",
    "    label = batch['label']\n",
    "    \n",
    "    predict = model(img)\n",
    "    _, pred_label = torch.max(predict, dim=1)\n",
    "    pred.append(pred_label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 label\n",
    "test_dataset = My_Dataset(test_dir)\n",
    "label = []\n",
    "for i in range(len(test_dataset)):\n",
    "    label.append(test_dataset[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 list비교 \n",
    "accuracy = np.mean(np.array(pred) == np.array(label))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
